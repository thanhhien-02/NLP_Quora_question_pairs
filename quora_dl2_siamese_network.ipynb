{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Next, we venture into Siamese Networks, specialized architectures designed for comparing and understanding relationships in textual data."
      ],
      "metadata": {
        "id": "EkFR2Et_L8vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A Siamese network is a type of neural network architecture designed for tasks involving similarity measurement or finding relationships between input samples. It's named after Siamese twins because the network structure involves two identical subnetworks (or twins) that share the same architecture and weights.**\n",
        "\n",
        "**The main purpose of a Siamese network**\\\n",
        "     to learn embeddings or representations of input data in such a way that similar inputs are mapped closer together in the embedding space while dissimilar inputs are farther apart. It's commonly used in tasks like:\n",
        "\n",
        "- Signature Verification: Determining if two signatures belong to the same person.\n",
        "- Face Recognition: Comparing faces to verify identity.\n",
        "- Similarity Matching: Comparing texts, images, or other data to find similarities.\n",
        "\n",
        "The network takes pairs of inputs and learns to output a similarity score or a distance metric that quantifies how similar the inputs are. During training, the network's parameters (weights and biases) are adjusted to minimize the distance between similar pairs and maximize the distance between dissimilar pairs.\n",
        "\n",
        "Siamese networks often use distance-based metrics like contrastive loss or triplet loss to train the network effectively. Contrastive loss aims to minimize the distance between similar pairs while pushing dissimilar pairs apart. Triplet loss works with three examples: an anchor, a positive example (similar to the anchor), and a negative example (dissimilar to the anchor).\n",
        "\n",
        "=> Overall, Siamese networks are valuable in learning representations that capture the essence of similarity between pairs of data points, enabling various applications in tasks that involve measuring similarity or dissimilarity."
      ],
      "metadata": {
        "id": "zi63nkUa1wFv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-28T04:46:26.161348Z",
          "iopub.status.busy": "2023-11-28T04:46:26.160180Z",
          "iopub.status.idle": "2023-11-28T04:46:28.357690Z",
          "shell.execute_reply": "2023-11-28T04:46:28.356572Z",
          "shell.execute_reply.started": "2023-11-28T04:46:26.161273Z"
        },
        "id": "eha7dRHu1rhU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import jaccard_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-28T04:46:28.360475Z",
          "iopub.status.busy": "2023-11-28T04:46:28.359702Z",
          "iopub.status.idle": "2023-11-28T04:46:30.093974Z",
          "shell.execute_reply": "2023-11-28T04:46:30.093019Z",
          "shell.execute_reply.started": "2023-11-28T04:46:28.360439Z"
        },
        "id": "DI0AmPUQ1rhY",
        "outputId": "99e3a1ad-cd31-4b6e-ea4b-0ca6a2b84da9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/kaggle/input/quora-question-pairs/train.csv.zip')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-28T04:46:30.096106Z",
          "iopub.status.busy": "2023-11-28T04:46:30.095520Z",
          "iopub.status.idle": "2023-11-28T04:46:30.304240Z",
          "shell.execute_reply": "2023-11-28T04:46:30.303103Z",
          "shell.execute_reply.started": "2023-11-28T04:46:30.096069Z"
        },
        "id": "h2U2a22r1rhZ",
        "outputId": "5617e9ce-a3c9-447e-81e6-f094bcae8429"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(404287, 6)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()\n",
        "df.dropna(inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-28T04:46:30.308158Z",
          "iopub.status.busy": "2023-11-28T04:46:30.307815Z",
          "iopub.status.idle": "2023-11-28T04:46:30.320174Z",
          "shell.execute_reply": "2023-11-28T04:46:30.318743Z",
          "shell.execute_reply.started": "2023-11-28T04:46:30.308131Z"
        },
        "id": "7T4KIDkp1rha"
      },
      "outputs": [],
      "source": [
        "# Remove the punctuation from the questions and apply some filters to the data\n",
        "import string\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_contractions(text):\n",
        "    # Define a list of common contractions and their expanded forms\n",
        "    contractions = {\n",
        "        \"don't\": \"do not\",\n",
        "        \"won't\": \"will not\",\n",
        "        \"can't\": \"cannot\",\n",
        "        # Add more contractions and their expansions as needed\n",
        "    }\n",
        "    for contraction, expansion in contractions.items():\n",
        "        text = text.replace(contraction, expansion)\n",
        "    return text\n",
        "\n",
        "def replace_currency_symbols(text):\n",
        "    # Define a dictionary mapping currency symbols to currency names\n",
        "    currency_symbols = {\n",
        "        \"$\": \"USD\",\n",
        "        \"€\": \"EUR\",\n",
        "        \"£\": \"GBP\",\n",
        "\n",
        "    }\n",
        "    for symbol, currency_name in currency_symbols.items():\n",
        "        text = text.replace(symbol, currency_name)\n",
        "    return text\n",
        "\n",
        "def remove_hyperlinks(text):\n",
        "    # Remove URLs and hyperlinks using regular expression\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    return text\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    # Remove HTML tags using regular expression\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    return text\n",
        "\n",
        "def process_column(column):\n",
        "    with Pool(cpu_count()) as pool:\n",
        "        processed_column = pool.map(remove_punctuation, column)\n",
        "        processed_column = pool.map(convert_to_lower, processed_column)\n",
        "        processed_column = pool.map(remove_contractions, processed_column)\n",
        "        processed_column = pool.map(replace_currency_symbols, processed_column)\n",
        "        processed_column = pool.map(remove_hyperlinks, processed_column)\n",
        "        processed_column = pool.map(remove_html_tags, processed_column)\n",
        "    return processed_column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-28T04:46:30.322844Z",
          "iopub.status.busy": "2023-11-28T04:46:30.322255Z",
          "iopub.status.idle": "2023-11-28T04:46:35.423303Z",
          "shell.execute_reply": "2023-11-28T04:46:35.421451Z",
          "shell.execute_reply.started": "2023-11-28T04:46:30.322797Z"
        },
        "id": "Vky2n51G1rhb",
        "outputId": "5ee1a5ec-daaf-459e-edff-548bfcd1f35a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what is the step by step guide to invest in sh...</td>\n",
              "      <td>what is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
              "      <td>what would happen if the indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how can i increase the speed of my internet co...</td>\n",
              "      <td>how can internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>why am i mentally very lonely how can i solve it</td>\n",
              "      <td>find the remainder when math2324math is divide...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
              "      <td>which fish would survive in salt water</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  \\\n",
              "0  what is the step by step guide to invest in sh...   \n",
              "1     what is the story of kohinoor kohinoor diamond   \n",
              "2  how can i increase the speed of my internet co...   \n",
              "3   why am i mentally very lonely how can i solve it   \n",
              "4  which one dissolve in water quikly sugar salt ...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  what is the step by step guide to invest in sh...             0  \n",
              "1  what would happen if the indian government sto...             0  \n",
              "2  how can internet speed be increased by hacking...             0  \n",
              "3  find the remainder when math2324math is divide...             0  \n",
              "4             which fish would survive in salt water             0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns_to_drop = ['id', 'qid1', 'qid2']\n",
        "df = df.drop(columns=columns_to_drop, axis=1)\n",
        "df['question1'] = process_column(df['question1'])\n",
        "df['question2'] = process_column(df['question2'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-28T04:46:35.425600Z",
          "iopub.status.busy": "2023-11-28T04:46:35.425175Z",
          "iopub.status.idle": "2023-11-28T10:01:43.541667Z",
          "shell.execute_reply": "2023-11-28T10:01:43.540459Z",
          "shell.execute_reply.started": "2023-11-28T04:46:35.425565Z"
        },
        "id": "l3bVpvtx1rhc",
        "outputId": "a96ab451-e600-40d0-eaac-46d7a51548a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10108/10108 [==============================] - ETA: 0s - loss: 0.5619 - accuracy: 0.6947"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10108/10108 [==============================] - 4041s 399ms/step - loss: 0.5619 - accuracy: 0.6947 - val_loss: 0.4948 - val_accuracy: 0.7662\n",
            "Epoch 2/5\n",
            "10108/10108 [==============================] - 4005s 396ms/step - loss: 0.4547 - accuracy: 0.7873 - val_loss: 0.4555 - val_accuracy: 0.7901\n",
            "Epoch 3/5\n",
            "10108/10108 [==============================] - 3793s 375ms/step - loss: 0.3943 - accuracy: 0.8230 - val_loss: 0.4353 - val_accuracy: 0.7994\n",
            "Epoch 4/5\n",
            "10108/10108 [==============================] - 3588s 355ms/step - loss: 0.3433 - accuracy: 0.8501 - val_loss: 0.4253 - val_accuracy: 0.8064\n",
            "Epoch 5/5\n",
            "10108/10108 [==============================] - 3397s 336ms/step - loss: 0.2994 - accuracy: 0.8727 - val_loss: 0.4209 - val_accuracy: 0.8116\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7af9c2d79ed0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda, Dense\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming 'question1' and 'question2' are your input questions\n",
        "# and 'is_duplicate' is the binary label indicating whether the questions are duplicates or not.\n",
        "questions1 = df['question1']\n",
        "questions2 = df['question2']\n",
        "labels = df['is_duplicate']\n",
        "\n",
        "# Assuming questions1, questions2, and labels are your input data\n",
        "# Fill missing values with empty strings\n",
        "questions1 = questions1.fillna('')\n",
        "questions2 = questions2.fillna('')\n",
        "\n",
        "# Tokenize your questions if needed\n",
        "max_sequence_length = 80\n",
        "embedding_dim = 300\n",
        "questions = df['question1'].astype(str) + ' ' + df['question2'].astype(str)\n",
        "\n",
        "tokens = [word for sentence in questions for word in sentence.split()]\n",
        "\n",
        "# Compute the vocabulary size\n",
        "vocabulary_size = len(set(tokens))\n",
        "questions = (questions1 + ' ' + questions2).astype(str)\n",
        "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
        "tokenizer.fit_on_texts(questions)\n",
        "\n",
        "sequences1 = tokenizer.texts_to_sequences(questions1)\n",
        "sequences2 = tokenizer.texts_to_sequences(questions2)\n",
        "padded_sequences1 = pad_sequences(sequences1, maxlen=max_sequence_length)\n",
        "padded_sequences2 = pad_sequences(sequences2, maxlen=max_sequence_length)\n",
        "\n",
        "input_layer1 = Input(shape=(max_sequence_length,))\n",
        "input_layer2 = Input(shape=(max_sequence_length,))\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim)\n",
        "\n",
        "lstm_layer = LSTM(units=50)\n",
        "\n",
        "x1 = embedding_layer(input_layer1)\n",
        "x1 = lstm_layer(x1)\n",
        "\n",
        "x2 = embedding_layer(input_layer2)\n",
        "x2 = lstm_layer(x2)\n",
        "\n",
        "distance_layer =  Lambda(lambda x: tf.keras.backend.abs(x[0] - x[1]),\n",
        "                               output_shape=lambda _: (1,))([x1, x2])\n",
        "\n",
        "output_layer = Dense(units=1, activation='sigmoid')(distance_layer)\n",
        "\n",
        "siamese_model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
        "\n",
        "siamese_model.compile(optimizer=Adam(0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath='siamese_model_weights.h5', save_best_only=True)\n",
        "]\n",
        "siamese_model.fit([padded_sequences1, padded_sequences2], labels, epochs=5, batch_size=32, validation_split=0.2, callbacks=callbacks)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 323734,
          "sourceId": 6277,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30587,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}